import os
import json
import numpy as np
import faiss
from openai import OpenAI
from flask import Flask, request, render_template

# âœ… åˆå§‹åŒ– Flask app
app = Flask(__name__)

# âœ… åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆå»ºè®®è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEYï¼‰
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# âœ… åŠ è½½åµŒå…¥å‘é‡ä¸ chunk æ–‡æœ¬
with open("id2chunks.json", "r", encoding="utf-8") as f:
    id2chunks = json.load(f)

with open("id2embeds.npy", "rb") as f:
    all_embeddings = np.load(f)

chunk_ids = list(id2chunks.keys())
embedding_dim = all_embeddings.shape[1]

# âœ… æ„å»º FAISS ç´¢å¼•
index = faiss.IndexFlatL2(embedding_dim)
index.add(all_embeddings)

# âœ… é¦–é¡µï¼šæé—®ç•Œé¢
@app.route("/", methods=["GET", "POST"])
def index():
    answer = ""
    retrieved_chunks = []
    
    if request.method == "POST":
        user_query = request.form.get("query")

        # ğŸ”¹ å‘é‡åŒ–ç”¨æˆ·é—®é¢˜
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=[user_query]
        )
        query_embed = np.array(response.data[0].embedding, dtype="float32").reshape(1, -1)

        # ğŸ”¹ FAISS æ£€ç´¢
        k = 5
        distances, indices = index.search(query_embed, k)
        for idx in indices[0]:
            chunk_id = chunk_ids[idx]
            retrieved_chunks.append(id2chunks[chunk_id])

        # ğŸ”¹ æ„é€  Prompt
        context = "\n\n".join(retrieved_chunks)
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªç†Ÿæ‚‰å—å¼€å¤§å­¦æ–°ç”ŸæŒ‡å—çš„æ ¡å›­åŠ©æ‰‹ï¼Œè¯·æ ¹æ®æä¾›çš„å†…å®¹ç”¨ä¸­æ–‡ç®€æ´æ˜äº†åœ°å›ç­”é—®é¢˜ã€‚"
        final_prompt = (
            f"ä»¥ä¸‹æ˜¯å—å¼€å¤§å­¦æ–°ç”ŸæŒ‡å—ä¸­çš„ç›¸å…³å†…å®¹ï¼š\n{context}\n\n"
            f"è¯·æ ¹æ®ä¸Šè¿°ä¿¡æ¯å›ç­”è¿™ä¸ªé—®é¢˜ï¼š{user_query}ã€‚\n"
            f"âš ï¸ æ³¨æ„ï¼šå°½é‡ç›´æ¥ä½¿ç”¨åŸæ–‡ä¸­çš„è¡¨è¿°ï¼Œä¸è¦ç”¨ä½ è‡ªå·±çš„è¯­è¨€æ”¹å†™ã€‚å¦‚æœèƒ½åŸå°ä¸åŠ¨å¼•ç”¨å°±å°½é‡å¼•ç”¨ï¼Œå›ç­”è¶Šè¯¦ç»†è¶Šå¥½ã€‚"
        )

        # ğŸ”¹ ç”Ÿæˆå›ç­”
        chat_response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": final_prompt}
            ],
            temperature=0.3
        )

        answer = chat_response.choices[0].message.content.strip()

    return render_template("index.html", answer=answer)

# âœ… å¯åŠ¨
if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=7860)
