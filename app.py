import os
import json
import numpy as np
import faiss
from openai import OpenAI
from flask import Flask, request, render_template, jsonify, session
from datetime import datetime
import uuid

# âœ… åˆå§‹åŒ– Flask app
app = Flask(__name__)
app.secret_key = os.environ.get("SECRET_KEY", "your-secret-key-here")  # ç”¨äº session

# âœ… åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

# âœ… æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
import os
print("å½“å‰ç›®å½•æ–‡ä»¶åˆ—è¡¨ï¼š", os.listdir('.'))

# âœ… åŠ è½½åµŒå…¥å‘é‡ä¸ chunk æ–‡æœ¬
# å¤„ç† JSONL æ ¼å¼æ–‡ä»¶
id2chunks = {}
jsonl_file = "nku_chunks_multilevel.jsonl"
npz_file = "nku_memory_vectors_full.npz"

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if not os.path.exists(jsonl_file):
    print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {jsonl_file}")
    exit(1)

if not os.path.exists(npz_file):
    print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {npz_file}")
    exit(1)

# âœ… åŠ è½½åµŒå…¥å‘é‡ä¸ chunk æ–‡æœ¬
id2chunks = {}
jsonl_file = "nku_chunks_multilevel.jsonl"
npz_file = "nku_memory_vectors_full.npz"

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if not os.path.exists(npz_file):
    print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {npz_file}")
    exit(1)

# é¦–å…ˆå°è¯•ä» NPZ æ–‡ä»¶ä¸­è¯»å–æ‰€æœ‰æ•°æ®
try:
    with np.load(npz_file) as data:
        print(f"NPZæ–‡ä»¶ä¸­çš„æ•°ç»„ï¼š{list(data.keys())}")
        
        # è¯»å–åµŒå…¥å‘é‡
        if 'all_embeddings' in data:
            all_embeddings = data['all_embeddings']
            print("ä½¿ç”¨æ•°ç»„ï¼šall_embeddings")
        elif 'embeddings' in data:
            all_embeddings = data['embeddings']
            print("ä½¿ç”¨æ•°ç»„ï¼šembeddings")
        elif 'vectors' in data:
            all_embeddings = data['vectors']
            print("ä½¿ç”¨æ•°ç»„ï¼švectors")
        else:
            # æŸ¥æ‰¾äºŒç»´æ•°ç»„ï¼ˆåµŒå…¥å‘é‡åº”è¯¥æ˜¯äºŒç»´çš„ï¼‰
            found_embedding = False
            for array_name in data.keys():
                if len(data[array_name].shape) == 2:
                    all_embeddings = data[array_name]
                    print(f"ä½¿ç”¨äºŒç»´æ•°ç»„ï¼š{array_name}")
                    found_embedding = True
                    break
            
            if not found_embedding:
                print("é”™è¯¯ï¼šæ‰¾ä¸åˆ°åˆé€‚çš„åµŒå…¥å‘é‡æ•°ç»„")
                exit(1)
        
        # å°è¯•ä» NPZ æ–‡ä»¶ä¸­è¯»å– id2chunks
        if 'id2chunks' in data:
            try:
                stored_id2chunks = data['id2chunks'].item()  # .item() ç”¨äºè¯»å–å­—å…¸
                print(f"ä»NPZæ–‡ä»¶è¯»å–åˆ° {len(stored_id2chunks)} ä¸ªæ–‡æ¡£å—")
                id2chunks = {str(k): str(v) for k, v in stored_id2chunks.items()}
            except:
                print("NPZä¸­çš„id2chunksè¯»å–å¤±è´¥ï¼Œå°†ä»JSONLæ–‡ä»¶è¯»å–")
                
    print(f"æˆåŠŸåŠ è½½åµŒå…¥å‘é‡ï¼Œå½¢çŠ¶ï¼š{all_embeddings.shape}")
except Exception as e:
    print(f"è¯»å–NPZæ–‡ä»¶å¤±è´¥ï¼š{e}")
    exit(1)

# å¦‚æœä» NPZ æ–‡ä»¶ä¸­æ²¡æœ‰æˆåŠŸè¯»å–åˆ° id2chunksï¼Œåˆ™ä» JSONL æ–‡ä»¶è¯»å–
if len(id2chunks) == 0:
    print("ä»JSONLæ–‡ä»¶è¯»å–æ–‡æ¡£å—...")
    if not os.path.exists(jsonl_file):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {jsonl_file}")
        exit(1)
    
    try:
        with open(jsonl_file, "r", encoding="utf-8") as f:
            for line_num, line in enumerate(f):
                if line.strip():  # è·³è¿‡ç©ºè¡Œ
                    try:
                        data = json.loads(line)
                        # ä½¿ç”¨è¡Œå·ä½œä¸º IDï¼Œæˆ–è€…ä½¿ç”¨æ•°æ®ä¸­çš„ id å­—æ®µ
                        chunk_id = str(line_num) if 'id' not in data else str(data['id'])
                        # å‡è®¾æ¯è¡ŒåŒ…å« 'text' æˆ– 'content' å­—æ®µ
                        chunk_text = data.get('text', data.get('content', line.strip()))
                        id2chunks[chunk_id] = chunk_text
                    except json.JSONDecodeError:
                        print(f"è­¦å‘Šï¼šç¬¬{line_num}è¡ŒJSONè§£æå¤±è´¥ï¼Œè·³è¿‡")
                        continue
        print(f"ä»JSONLæ–‡ä»¶æˆåŠŸåŠ è½½ {len(id2chunks)} ä¸ªæ–‡æ¡£å—")
    except Exception as e:
        print(f"è¯»å–JSONLæ–‡ä»¶å¤±è´¥ï¼š{e}")
        exit(1)

print(f"æœ€ç»ˆåŠ è½½äº† {len(id2chunks)} ä¸ªæ–‡æ¡£å—å’Œ {all_embeddings.shape} çš„åµŒå…¥å‘é‡")

chunk_ids = list(id2chunks.keys())
embedding_dim = all_embeddings.shape[1]

# âœ… æ„å»º FAISS ç´¢å¼•
index = faiss.IndexFlatL2(embedding_dim)
index.add(all_embeddings)

# âœ… åœ¨å†…å­˜ä¸­å­˜å‚¨ä¼šè¯å†å²ï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨æ•°æ®åº“ï¼‰
chat_sessions = {}

def get_session_id():
    """è·å–æˆ–åˆ›å»ºä¼šè¯ID"""
    if 'session_id' not in session:
        session['session_id'] = str(uuid.uuid4())
    return session['session_id']

def get_chat_history(session_id):
    """è·å–èŠå¤©å†å²"""
    if session_id not in chat_sessions:
        chat_sessions[session_id] = []
    return chat_sessions[session_id]

def add_to_chat_history(session_id, user_message, assistant_response, retrieved_chunks):
    """æ·»åŠ åˆ°èŠå¤©å†å²"""
    if session_id not in chat_sessions:
        chat_sessions[session_id] = []
    
    chat_sessions[session_id].append({
        'id': str(uuid.uuid4()),
        'timestamp': datetime.now().isoformat(),
        'user_message': user_message,
        'assistant_response': assistant_response,
        'retrieved_chunks': retrieved_chunks
    })

def retrieve_relevant_chunks(user_query, k=5):
    """æ£€ç´¢ç›¸å…³æ–‡æ¡£å—"""
    # ğŸ”¹ å‘é‡åŒ–ç”¨æˆ·é—®é¢˜
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=[user_query]
    )
    query_embed = np.array(response.data[0].embedding, dtype="float32").reshape(1, -1)
    
    # ğŸ”¹ FAISS æ£€ç´¢
    distances, indices = index.search(query_embed, k)
    
    retrieved_chunks = []
    for idx in indices[0]:
        chunk_id = chunk_ids[idx]
        retrieved_chunks.append(id2chunks[chunk_id])
    
    return retrieved_chunks

def generate_response(user_query, chat_history, retrieved_chunks):
    """ç”Ÿæˆå›ç­”"""
    # ğŸ”¹ æ„é€  context
    context = "\n\n".join(retrieved_chunks)
    
    # ğŸ”¹ å‡†å¤‡æ¶ˆæ¯å†å²
    messages = [
        {
            "role": "system", 
            "content": "ä½ æ˜¯ä¸€ä¸ªç†Ÿæ‚‰å—å¼€å¤§å­¦æ–°ç”ŸæŒ‡å—çš„æ ¡å›­åŠ©æ‰‹ï¼Œè¯·æ ¹æ®æä¾›çš„å†…å®¹ç”¨ä¸­æ–‡ç®€æ´æ˜äº†åœ°å›ç­”é—®é¢˜ã€‚è¯·ä¿æŒå¯¹è¯çš„è¿è´¯æ€§ï¼Œå¯ä»¥å‚è€ƒä¹‹å‰çš„å¯¹è¯å†…å®¹ã€‚"
        }
    ]
    
    # ğŸ”¹ æ·»åŠ å†å²å¯¹è¯ï¼ˆæœ€è¿‘5è½®ï¼Œé¿å… token è¿‡å¤šï¼‰
    recent_history = chat_history[-5:] if len(chat_history) > 5 else chat_history
    for chat in recent_history:
        messages.append({"role": "user", "content": chat['user_message']})
        messages.append({"role": "assistant", "content": chat['assistant_response']})
    
    # ğŸ”¹ æ„é€ å½“å‰é—®é¢˜çš„ prompt
    current_prompt = (
        f"ä»¥ä¸‹æ˜¯å—å¼€å¤§å­¦æ–°ç”ŸæŒ‡å—ä¸­çš„ç›¸å…³å†…å®¹ï¼š\n{context}\n\n"
        f"è¯·æ ¹æ®ä¸Šè¿°ä¿¡æ¯å›ç­”è¿™ä¸ªé—®é¢˜ï¼š{user_query}\n"
        f"âš ï¸ æ³¨æ„ï¼šå°½é‡ç›´æ¥ä½¿ç”¨åŸæ–‡ä¸­çš„è¡¨è¿°ï¼Œä¸è¦ç”¨ä½ è‡ªå·±çš„è¯­è¨€æ”¹å†™ã€‚å¦‚æœèƒ½åŸå°ä¸åŠ¨å¼•ç”¨å°±å°½é‡å¼•ç”¨ï¼Œå›ç­”è¶Šè¯¦ç»†è¶Šå¥½ã€‚"
    )
    
    messages.append({"role": "user", "content": current_prompt})
    
    # ğŸ”¹ ç”Ÿæˆå›ç­”
    chat_response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.3
    )
    
    return chat_response.choices[0].message.content.strip()

# âœ… é¦–é¡µï¼šèŠå¤©ç•Œé¢
@app.route("/")
def index():
    return render_template("chat.html")

# âœ… è·å–èŠå¤©å†å²
@app.route("/api/history")
def get_history():
    session_id = get_session_id()
    history = get_chat_history(session_id)
    return jsonify(history)

# âœ… å‘é€æ¶ˆæ¯
@app.route("/api/chat", methods=["POST"])
def chat():
    try:
        data = request.get_json()
        user_query = data.get("message", "").strip()
        
        if not user_query:
            return jsonify({"error": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"}), 400
        
        session_id = get_session_id()
        chat_history = get_chat_history(session_id)
        
        # ğŸ”¹ æ£€ç´¢ç›¸å…³å†…å®¹
        retrieved_chunks = retrieve_relevant_chunks(user_query)
        
        # ğŸ”¹ ç”Ÿæˆå›ç­”
        assistant_response = generate_response(user_query, chat_history, retrieved_chunks)
        
        # ğŸ”¹ æ·»åŠ åˆ°å†å²è®°å½•
        add_to_chat_history(session_id, user_query, assistant_response, retrieved_chunks)
        
        return jsonify({
            "response": assistant_response,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"Error: {e}")
        return jsonify({"error": "å¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯"}), 500

# âœ… æ¸…ç©ºèŠå¤©å†å²
@app.route("/api/clear", methods=["POST"])
def clear_history():
    session_id = get_session_id()
    if session_id in chat_sessions:
        chat_sessions[session_id] = []
    return jsonify({"message": "èŠå¤©å†å²å·²æ¸…ç©º"})

# âœ… å¯åŠ¨
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 7860))
    app.run(debug=False, host="0.0.0.0", port=port)
